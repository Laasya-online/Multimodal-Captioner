## BLIP Multimodal Captioner

This mini-project uses the `Salesforce/blip-image-captioning-base` model in a
Colab notebook to generate captions for a few images (e.g., aircraft, spaceports).

### Tech Stack used:

- Python 3
- Google Colab (development + GPU runtime)
- Hugging Face Transformers (transformers) for model loading & inference
- BLIP Image Captioning Model: Salesforce/blip-image-captioning-base
- timm for vision backbone support
- accelerate for optimized performance on GPU
- Pillow (PIL) for image manipulation
